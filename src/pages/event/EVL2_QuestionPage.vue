<template>
  <div class="flex h-full flex-col">
    <!-- ìƒë‹¨ Title -->
    <div class="text-primary-500 mb-8 text-2xl font-bold">
      ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”
    </div>

    <!-- ì¤‘ë‹¨ ì„¤ëª… -->
    <div class="text-surface-500 mb-8 space-y-1 text-base leading-relaxed">
      <p>ì–´ë ¤ìš´ ê¸ˆìœµ ë‹¨ì–´ê°€ ìˆìœ¼ì‹ ê°€ìš”?</p>
      <p>ê¶ê¸ˆí•œì ì„ ì…ë ¥í•´ì£¼ì‹œê±°ë‚˜,</p>
      <p>ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ì„œ ì•Œë ¤ì£¼ì„¸ìš”.</p>
      <p>ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”!</p>
    </div>

    <!-- í•˜ë‹¨ ì…ë ¥ ì˜ì—­ -->
    <div class="flex flex-1 flex-col justify-end space-y-6">
      <!-- í…ìŠ¤íŠ¸ë¡œ ë¬¼ì–´ë³´ê¸° ì„¹ì…˜ -->
      <div class="space-y-3">
        <h3 class="text-primary-500 text-lg font-semibold"
          >ğŸ’¬ í‚¤ë³´ë“œë¡œ ë¬¼ì–´ë³´ê¸°</h3
        >
        <InputBox
          v-model="questionText"
          size="large"
          placeholder="ê¶ê¸ˆí•œ ê¸ˆìœµ ë‹¨ì–´ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”!"
          class="w-full"
        />
        <button
          @click="submitTextQuestion"
          :disabled="!questionText.trim()"
          :class="[
            'w-full rounded-lg py-3 font-semibold text-white transition-colors',
            questionText.trim()
              ? 'bg-primary-500'
              : 'bg-surface-300 cursor-not-allowed',
          ]"
        >
          í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ê¸°
        </button>
      </div>

      <div class="border-surface-200 border-t"></div>

      <!-- ìŒì„±ìœ¼ë¡œ ë¬¼ì–´ë³´ê¸° ì„¹ì…˜ -->
      <div class="space-y-3">
        <h3 class="text-primary-500 text-lg font-semibold"
          >ğŸ¤ ë§ˆì´í¬ë¡œ ë¬¼ì–´ë³´ê¸°</h3
        >

        <!-- ìŒì„± ì…ë ¥ ë²„íŠ¼ -->
        <div class="flex justify-center">
          <button
            @click="toggleRecording"
            :class="[
              'flex h-20 w-20 items-center justify-center rounded-full shadow-lg transition-all duration-300',
              isRecording
                ? 'animate-pulse bg-red-500 hover:bg-red-600'
                : 'bg-primary-500 hover:bg-primary-600',
            ]"
            :disabled="isProcessing"
          >
            <svg
              v-if="!isRecording"
              class="h-10 w-10 text-white"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <path
                d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z"
              />
            </svg>
            <svg
              v-else
              class="h-10 w-10 text-white"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <path d="M6 6h12v12H6z" />
            </svg>
          </button>
        </div>

        <!-- ë…¹ìŒ ìƒíƒœ í‘œì‹œ -->
        <div v-if="isRecording" class="text-center">
          <p class="text-sm font-medium text-red-500">
            ë…¹ìŒ ì¤‘... ({{ recordingTime }}ì´ˆ)
          </p>
          <p class="text-surface-500 mt-1 text-sm">
            ë§ˆì´í¬ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ë…¹ìŒì„ ì¢…ë£Œí•˜ì„¸ìš”
          </p>
        </div>

        <div v-if="isProcessing" class="text-center">
          <p class="text-primary-500 text-sm font-medium">
            ìŒì„±ì„ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤...
          </p>
        </div>

        <p class="text-surface-400 text-center text-sm">
          ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒí•˜ê³ , ë‹¤ì‹œ ëˆŒëŸ¬ ì „ì†¡í•˜ì„¸ìš”
        </p>
      </div>
    </div>

    <!-- Alert ëª¨ë‹¬ -->
    <Alert v-if="showAlert" :title="alertTitle" @click="closeAlert">
      <!-- ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš° -->
      <div v-if="!currentResponse" class="text-red-600">
        {{ alertContent }}
      </div>

      <!-- ì„±ê³µ ì‘ë‹µì¸ ê²½ìš° -->
      <div v-else class="space-y-4">
        <!-- ì§ˆë¬¸í•˜ì‹  ë‚´ìš© -->
        <div v-if="currentResponse.processedText" class="space-y-2">
          <h4 class="text-primary-600 text-lg font-semibold"
            >ì§ˆë¬¸í•˜ì‹  ë‚´ìš© :</h4
          >
          <p class="text-surface-500 bg-surface-100 rounded-lg p-3 text-base">
            "{{ currentResponse.processedText }}"
          </p>
        </div>

        <!-- ì„¤ëª… -->
        <div v-if="currentResponse.aiResponse" class="space-y-2">
          <h4 class="text-primary-600 text-lg font-semibold">ì„¤ëª…ì´ì—ìš” :</h4>
          <p
            class="text-surface-500 bg-surface-100 rounded-lg p-3 text-base leading-relaxed"
          >
            {{ currentResponse.aiResponse }}
          </p>
        </div>
      </div>
    </Alert>
  </div>
</template>

<script setup lang="ts">
import { ref, onUnmounted } from 'vue';
import InputBox from '@/components/forms/InputBox.vue';
import Alert from '@/components/modals/Alert.vue';
import { questionApi, type QuestionResponse } from '@/api/question/question';

const questionText = ref('');
const isRecording = ref(false);
const isProcessing = ref(false);
const recordingTime = ref(0);
const audioBlob = ref<Blob | null>(null);

// Alert ëª¨ë‹¬ ìƒíƒœ
const showAlert = ref(false);
const alertTitle = ref('');
const alertContent = ref('');
const currentResponse = ref<QuestionResponse | null>(null);

let mediaRecorder: MediaRecorder | null = null;
let recordingTimer: number | null = null;
let audioChunks: BlobPart[] = [];

const toggleRecording = async () => {
  if (!isRecording.value) {
    await startRecording();
  } else {
    stopRecording();
  }
};

const startRecording = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream, {
      mimeType: MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : 'audio/webm',
    });

    audioChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    mediaRecorder.onstop = () => {
      const mimeType = mediaRecorder?.mimeType || 'audio/webm';
      audioBlob.value = new Blob(audioChunks, { type: mimeType });

      stream.getTracks().forEach((track) => track.stop());

      // ìŒì„± ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ API í˜¸ì¶œ
      submitVoiceQuestion();
    };

    mediaRecorder.start();
    isRecording.value = true;
    recordingTime.value = 0;

    recordingTimer = window.setInterval(() => {
      recordingTime.value++;
    }, 1000);
  } catch (error) {
    console.error('ìŒì„± ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
    alert('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
  }
};

const stopRecording = () => {
  if (mediaRecorder && isRecording.value) {
    isRecording.value = false;
    mediaRecorder.stop();

    if (recordingTimer) {
      clearInterval(recordingTimer);
      recordingTimer = null;
    }
  }
};

// í…ìŠ¤íŠ¸ ì „ìš© ì§ˆë¬¸ ì œì¶œ
const submitTextQuestion = async () => {
  if (!questionText.value.trim()) {
    return;
  }

  try {
    isProcessing.value = true;

    console.log('í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì „ì†¡ ì‹œì‘...');
    const response: QuestionResponse = await questionApi.askTextOnly(
      questionText.value
    );

    console.log('=== í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì‘ë‹µ ===');
    console.log('ìƒíƒœ:', response.status);
    console.log('ë©”ì‹œì§€:', response.message);
    if (response.processedText) {
      console.log('ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸:', response.processedText);
    }
    if (response.aiResponse) {
      console.log('AI ì‘ë‹µ:', response.aiResponse);
    }
    console.log('===================');

    if (response.status === 'SUCCESS') {
      questionText.value = '';
      showSuccessAlert(response);
    } else {
      showErrorAlert(response.message);
    }
  } catch (error) {
    console.error('í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì „ì†¡ ì‹¤íŒ¨:', error);
    showErrorAlert('í…ìŠ¤íŠ¸ ì§ˆë¬¸ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
  } finally {
    isProcessing.value = false;
  }
};

// ìŒì„± ì „ìš© ì§ˆë¬¸ ì œì¶œ
const submitVoiceQuestion = async () => {
  if (!audioBlob.value) {
    return;
  }

  try {
    isProcessing.value = true;

    // ìŒì„± íŒŒì¼ì„ File ê°ì²´ë¡œ ë³€í™˜
    const fileName = `voice_question_${Date.now()}.webm`;
    const audioFile = new File([audioBlob.value], fileName, {
      type: audioBlob.value.type,
    });

    console.log('ìŒì„± ì§ˆë¬¸ ì „ì†¡ ì‹œì‘...');
    const response: QuestionResponse =
      await questionApi.askVoiceOnly(audioFile);

    console.log('=== ìŒì„± ì§ˆë¬¸ ì‘ë‹µ ===');
    console.log('ìƒíƒœ:', response.status);
    console.log('ë©”ì‹œì§€:', response.message);
    if (response.processedText) {
      console.log('ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸:', response.processedText);
    }
    if (response.aiResponse) {
      console.log('AI ì‘ë‹µ:', response.aiResponse);
    }
    console.log('===================');

    if (response.status === 'SUCCESS') {
      audioBlob.value = null;
      showSuccessAlert(response);
    } else {
      showErrorAlert(response.message);
    }
  } catch (error) {
    console.error('ìŒì„± ì§ˆë¬¸ ì „ì†¡ ì‹¤íŒ¨:', error);
    showErrorAlert('ìŒì„± ì§ˆë¬¸ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
  } finally {
    isProcessing.value = false;
  }
};

// Alert ëª¨ë‹¬ ì œì–´ í•¨ìˆ˜ë“¤
const showSuccessAlert = (response: QuestionResponse) => {
  currentResponse.value = response;
  alertTitle.value = 'ğŸ’¡ ì„¤ëª… ì™„ë£Œ!';
  showAlert.value = true;
};

const showErrorAlert = (message: string) => {
  currentResponse.value = null;
  alertTitle.value = 'âš ï¸ ì˜¤ë¥˜ ë°œìƒ';
  alertContent.value = message;
  showAlert.value = true;
};

const closeAlert = () => {
  showAlert.value = false;
  alertTitle.value = '';
  alertContent.value = '';
  currentResponse.value = null;
};

onUnmounted(() => {
  if (recordingTimer) {
    clearInterval(recordingTimer);
  }
  if (mediaRecorder && isRecording.value) {
    stopRecording();
  }
});
</script>
